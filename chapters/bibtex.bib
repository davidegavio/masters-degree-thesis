@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{song2020mpnet,
  title={Mpnet: Masked and permuted pre-training for language understanding},
  author={Song, Kaitao and Tan, Xu and Qin, Tao and Lu, Jianfeng and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:2004.09297},
  year={2020}
}

@article{lample2019cross,
  title={Cross-lingual language model pretraining},
  author={Lample, Guillaume and Conneau, Alexis},
  journal={arXiv preprint arXiv:1901.07291},
  year={2019}
}

@article{zaharia2010spark,
  title={Spark: Cluster computing with working sets.},
  author={Zaharia, Matei and Chowdhury, Mosharaf and Franklin, Michael J and Shenker, Scott and Stoica, Ion and others},
  journal={HotCloud},
  volume={10},
  number={10-10},
  pages={95},
  year={2010}
}

@article{dean2004mapreduce,
  title={MapReduce: Simplified data processing on large clusters},
  author={Dean, Jeffrey and Ghemawat, Sanjay},
  year={2004}
}

@book{leskovec_rajaraman_ullman_2020, 
    place={Cambridge}, 
    edition={3}, 
    title={Mining of Massive Datasets}, 
    DOI={10.1017/9781108684163}, 
    publisher={Cambridge University Press}, 
    author={Leskovec, Jure and Rajaraman, Anand and Ullman, Jeffrey David}, year={2020}}
    
@misc{artea,
      title = {artea.com},
      howpublished = {\url{https://artea.com/}}
}

@incollection{cosine_HAN201239,
            title = {2 - Getting to Know Your Data},
            editor = {Jiawei Han and Micheline Kamber and Jian Pei},
            booktitle = {Data Mining (Third Edition)},
            publisher = {Morgan Kaufmann},
            edition = {Third Edition},
            address = {Boston},
            pages = {39-82},
            year = {2012},
            series = {The Morgan Kaufmann Series in Data Management Systems},
            isbn = {978-0-12-381479-1},
            doi = {https://doi.org/10.1016/B978-0-12-381479-1.00002-2},
            url = {https://www.sciencedirect.com/science/article/pii/B9780123814791000022},
            author = {Jiawei Han and Micheline Kamber and Jian Pei}
}

@article{mikolov2013efficient,
  title={Efficient estimation of word representations in vector space},
  author={Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  journal={arXiv preprint arXiv:1301.3781},
  year={2013}
}

@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}

@article{Gandomi2015BeyondTH,
  title={Beyond the hype: Big data concepts, methods, and analytics},
  author={A. Gandomi and Murtaza Haider},
  journal={Int. J. Inf. Manag.},
  year={2015},
  volume={35},
  pages={137-144}
}

@misc{bigdatagartner,
      title = {Big Data},
      howpublished = {\url{https://www.gartner.com/en/information-technology/glossary/big-data}}
}

@misc{SOA_ibm,
      title = {SOA (Service-Oriented Architecture)},
      howpublished = {\url{https://www.ibm.com/cloud/learn/soa}}
}

@misc{microservices_ibm,
      title = {Microservices},
      howpublished = {\url{https://www.ibm.com/cloud/learn/microservices}}
}

@misc{html_parser,
      title = {html.parser — Simple HTML and XHTML parser},
      howpublished = {\url{https://docs.python.org/3/library/html.parser.html}}
}

@misc{sbert,
      title = {SentenceTransformers},
      howpublished = {\url{https://www.sbert.net/}}
}

@misc{reimers2019sentencebert,
      title={Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks}, 
      author={Nils Reimers and Iryna Gurevych},
      year={2019},
      eprint={1908.10084},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{huggingface,
      title = {Hugging Face},
      howpublished = {\url{https://huggingface.co/}}
}

@article{Siu1998IntroductionTG,
  title={Introduction to graph theory (4th edition), by Robin J. Wilson. Pp. 171. £14.99. 1996. ISBN : 0-582-24993-7 (Longman).},
  author={M. Siu},
  journal={The Mathematical Gazette},
  year={1998},
  volume={82},
  pages={343-344}
}

@book{books/daglib/0029345,
  added-at = {2012-11-06T00:00:00.000+0100},
  author = {Sedgewick, Robert and Wayne, Kevin},
  biburl = {https://www.bibsonomy.org/bibtex/22fde79ee322687a901feb1b1823bb447/dblp},
  interhash = {552396c14a0129abbe40ca305b4f001b},
  intrahash = {2fde79ee322687a901feb1b1823bb447},
  isbn = {978-0-321-57351-3},
  keywords = {dblp},
  pages = {I-XII, 1-955},
  publisher = {Addison-Wesley},
  timestamp = {2012-11-07T11:41:50.000+0100},
  title = {Algorithms, 4th Edition.},
  year = 2011
}

@ARTICLE{2020SciPyNMeth,
  author  = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and
            Haberland, Matt and Reddy, Tyler and Cournapeau, David and
            Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and
            Bright, Jonathan and {van der Walt}, St{\'e}fan J. and
            Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and
            Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and
            Kern, Robert and Larson, Eric and Carey, C J and
            Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and
            {VanderPlas}, Jake and Laxalde, Denis and Perktold, Josef and
            Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and
            Harris, Charles R. and Archibald, Anne M. and
            Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and
            {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
  title   = {{{SciPy} 1.0: Fundamental Algorithms for Scientific
            Computing in Python}},
  journal = {Nature Methods},
  year    = {2020},
  volume  = {17},
  pages   = {261--272},
  adsurl  = {https://rdcu.be/b08Wh},
  doi     = {10.1038/s41592-019-0686-2},
}

@article{DBLP:journals/corr/abs-2010-16061,
  author    = {David M. W. Powers},
  title     = {Evaluation: from precision, recall and F-measure to ROC, informedness,
               markedness and correlation},
  journal   = {CoRR},
  volume    = {abs/2010.16061},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.16061},
  archivePrefix = {arXiv},
  eprint    = {2010.16061},
  timestamp = {Tue, 03 Nov 2020 11:44:23 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-16061.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Article{         harris2020array,
 title         = {Array programming with {NumPy}},
 author        = {Charles R. Harris and K. Jarrod Millman and St{\'{e}}fan J.
                 van der Walt and Ralf Gommers and Pauli Virtanen and David
                 Cournapeau and Eric Wieser and Julian Taylor and Sebastian
                 Berg and Nathaniel J. Smith and Robert Kern and Matti Picus
                 and Stephan Hoyer and Marten H. van Kerkwijk and Matthew
                 Brett and Allan Haldane and Jaime Fern{\'{a}}ndez del
                 R{\'{i}}o and Mark Wiebe and Pearu Peterson and Pierre
                 G{\'{e}}rard-Marchant and Kevin Sheppard and Tyler Reddy and
                 Warren Weckesser and Hameer Abbasi and Christoph Gohlke and
                 Travis E. Oliphant},
 year          = {2020},
 month         = sep,
 journal       = {Nature},
 volume        = {585},
 number        = {7825},
 pages         = {357--362},
 doi           = {10.1038/s41586-020-2649-2},
 publisher     = {Springer Science and Business Media {LLC}},
 url           = {https://doi.org/10.1038/s41586-020-2649-2}
}

@article{DBLP:journals/corr/abs-1810-04805,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  journal   = {CoRR},
  volume    = {abs/1810.04805},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.04805},
  archivePrefix = {arXiv},
  eprint    = {1810.04805},
  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2004-09297,
  author    = {Kaitao Song and
               Xu Tan and
               Tao Qin and
               Jianfeng Lu and
               Tie{-}Yan Liu},
  title     = {MPNet: Masked and Permuted Pre-training for Language Understanding},
  journal   = {CoRR},
  volume    = {abs/2004.09297},
  year      = {2020},
  url       = {https://arxiv.org/abs/2004.09297},
  archivePrefix = {arXiv},
  eprint    = {2004.09297},
  timestamp = {Fri, 04 Dec 2020 15:21:07 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2004-09297.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1910-01108,
  author    = {Victor Sanh and
               Lysandre Debut and
               Julien Chaumond and
               Thomas Wolf},
  title     = {DistilBERT, a distilled version of {BERT:} smaller, faster, cheaper
               and lighter},
  journal   = {CoRR},
  volume    = {abs/1910.01108},
  year      = {2019},
  url       = {http://arxiv.org/abs/1910.01108},
  archivePrefix = {arXiv},
  eprint    = {1910.01108},
  timestamp = {Tue, 02 Jun 2020 12:48:59 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1910-01108.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1909-11942,
  author    = {Zhenzhong Lan and
               Mingda Chen and
               Sebastian Goodman and
               Kevin Gimpel and
               Piyush Sharma and
               Radu Soricut},
  title     = {{ALBERT:} {A} Lite {BERT} for Self-supervised Learning of Language
               Representations},
  journal   = {CoRR},
  volume    = {abs/1909.11942},
  year      = {2019},
  url       = {http://arxiv.org/abs/1909.11942},
  archivePrefix = {arXiv},
  eprint    = {1909.11942},
  timestamp = {Fri, 27 Sep 2019 13:04:21 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1909-11942.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1901-07291,
  author    = {Guillaume Lample and
               Alexis Conneau},
  title     = {Cross-lingual Language Model Pretraining},
  journal   = {CoRR},
  volume    = {abs/1901.07291},
  year      = {2019},
  url       = {http://arxiv.org/abs/1901.07291},
  archivePrefix = {arXiv},
  eprint    = {1901.07291},
  timestamp = {Fri, 01 Feb 2019 13:39:59 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1901-07291.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{bert_blog_post,
      title = {Open Sourcing BERT: State-of-the-Art Pre-training for Natural Language Processing},
      howpublished = {\url{https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html}}
}

@misc{albert_blog_post,
      title = {ALBERT: A Lite BERT for Self-Supervised Learning of Language Representations},
      howpublished = {\url{https://ai.googleblog.com/2019/12/albert-lite-bert-for-self-supervised.html}}
}

@misc{distilbert_blog_post,
      title = {Smaller, faster, cheaper, lighter: Introducing DistilBERT, a distilled version of BERT},
      howpublished = {\url{https://medium.com/huggingface/distilbert-8cf3380435b5}}
}

@online{sentence-transformers,
  title={SentenceTransformers },
  url={https://www.sbert.net/index.html},
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@InProceedings{SciPyProceedings_11,
  author =       {Aric A. Hagberg and Daniel A. Schult and Pieter J. Swart},
  title =        {Exploring Network Structure, Dynamics, and Function using NetworkX},
  booktitle =   {Proceedings of the 7th Python in Science Conference},
  pages =     {11 - 15},
  address = {Pasadena, CA USA},
  year =      {2008},
  editor =    {Ga\"el Varoquaux and Travis Vaught and Jarrod Millman},
}

@misc{mpnet_blog_post,
      title = {MPNet combines strengths of masked and permuted language modeling for language understanding},
      howpublished = {\url{https://www.microsoft.com/en-us/research/blog/mpnet-combines-strengths-of-masked-and-permuted-language-modeling-for-language-understanding/}}
}

@misc{xlm_blog_post,
      title = {Cross-lingual pretraining sets new state of the art for natural language understanding},
      howpublished = {\url{https://ai.facebook.com/blog/cross-lingual-pretraining/}}
}

@inproceedings{10.1145/1150402.1150464,
author = {Buciluundefined, Cristian and Caruana, Rich and Niculescu-Mizil, Alexandru},
title = {Model Compression},
year = {2006},
isbn = {1595933395},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1150402.1150464},
doi = {10.1145/1150402.1150464},
abstract = {Often the best performing supervised learning models are ensembles of hundreds or
thousands of base-level classifiers. Unfortunately, the space required to store this
many classifiers, and the time required to execute them at run-time, prohibits their
use in applications where test sets are large (e.g. Google), where storage space is
at a premium (e.g. PDAs), and where computational power is limited (e.g. hea-ring
aids). We present a method for "compressing" large, complex ensembles into smaller,
faster models, usually without significant loss in performance.},
booktitle = {Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {535–541},
numpages = {7},
keywords = {supervised learning, model compression},
location = {Philadelphia, PA, USA},
series = {KDD '06}
}

@misc{hinton2015distilling,
      title={Distilling the Knowledge in a Neural Network}, 
      author={Geoffrey Hinton and Oriol Vinyals and Jeff Dean},
      year={2015},
      eprint={1503.02531},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}


