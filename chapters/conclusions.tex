\providecommand{\main}{..}
\documentclass[\main/main.tex]{subfiles}
\begin{document}
\chapter{Conclusions}
\section{Project conclusions}
The Proof of Concept (PoC) presented in this document consists of a ``Semantic Search Engine'' able to semantically rank documents given a query at search time based entirely on Transformer technology, able to capture the context and the relations inside given documents. \\
It has been demonstrated throughout the project development that an approach like the one described in this document could be helpful in context where there is a big quantity of documents and a human has to manually search within this corpus. Using this framework is possible to retrieve the most pertinent result(s) for a given query. \\
An important aspect that emerges from the document is that the model choice is absolutely crucial: the more specialized the model is for the task, the better the results obtainable. As visible in Chapter 5, using generic models such as \emph{distilbert-base-multilingual-cased} or \emph{albert-base-v2} led to inconsistent results, while using a model like \emph{stsb-mpnet-base-v2} which is designed to work well in similarity tasks return better results.

\section{Future work}
As previously said, due to time constraints, it hasn't been possible to test the system on a bigger portion of the dataset so a possible further improvement could be given by the application of the framework on a different and bigger portion of the dataset. \\
As said in Chapter 1, one of the main challenges has been dealing with long documents: an improvement to this work could be testing a different kind of document vectorization, perhaps adding a previous information retrieval layer able to extract relevant text portions and then vectorize only these parts, reducing computational and memory load. Speaking about the algorithmic part of the project, every further possible enhancement could constitute a future work. Supervised approaches and different similarity computation methods could bring benefit to the final result.\\
Another future work, should be testing the framework on a dataset coming from a completely different domain. As previously stated, the system is able to work with every kind of textual document from a technical point of view, but speaking about performances it is not as easy as it seems: the best model for the current dataset could be the worst for another dataset, the cleaning approach applied could be harmful when applied on another dataset and so on.\\
Wrapping the framework inside an application architecture to allow the runtime computation of needed similarities will be another important future work. \\
Lastly, an interesting contribution could be specializing a chosen model for the current dataset in order to theoretically obtain even better result than the starting model.
\end{document}