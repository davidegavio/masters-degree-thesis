\providecommand{\main}{..}
\documentclass[\main/main.tex]{subfiles}
\colorlet{punct}{red!60!black}
\definecolor{background}{HTML}{EEEEEE}
\definecolor{delim}{RGB}{20,105,176}
\colorlet{numb}{magenta!60!black}

\lstdefinelanguage{json}{
    basicstyle=\normalfont\ttfamily,
    numbers=left,
    numberstyle=\scriptsize,
    stepnumber=1,
    numbersep=8pt,
    showstringspaces=false,
    breaklines=true,
    frame=lines,
    backgroundcolor=\color{background},
    literate=
     *{0}{{{\color{numb}0}}}{1}
      {1}{{{\color{numb}1}}}{1}
      {2}{{{\color{numb}2}}}{1}
      {3}{{{\color{numb}3}}}{1}
      {4}{{{\color{numb}4}}}{1}
      {5}{{{\color{numb}5}}}{1}
      {6}{{{\color{numb}6}}}{1}
      {7}{{{\color{numb}7}}}{1}
      {8}{{{\color{numb}8}}}{1}
      {9}{{{\color{numb}9}}}{1}
      {:}{{{\color{punct}{:}}}}{1}
      {,}{{{\color{punct}{,}}}}{1}
      {\{}{{{\color{delim}{\{}}}}{1}
      {\}}{{{\color{delim}{\}}}}}{1}
      {[}{{{\color{delim}{[}}}}{1}
      {]}{{{\color{delim}{]}}}}{1},
}
\begin{document}
\chapter{Experiments and results}
\section{Experimental setup}
Due to computation time constraints, it has not been possible to perform experiments on the whole document corpus made available by \emph{artea.com}. Thus, the dataset has been reduced in order to make possible the execution of different experiments in a reasonable time. As mentioned before in Chapter 4, a resulting dataset of 100 records has been created. For each of 10 queries, 5 related and 5 not related documents were searched manually. Each record is a key-value pair object composed like Listing \ref{exp_dataset_object}:
\begin{center}
    \begin{lstlisting}[language=json, caption="Experimental dataset object", captionpos=b, label={exp_dataset_object}]
        {
         "query_document_key": "query_key",
         "query_field_0": "value",
         ...: ...,
         "query_field_n": "value",
         "search_document_key": "search_key"
         "search_field_0": "value",
         ...: ...,
         "search_field_n": "value",
         "relation": "true"
        }
    
    \end{lstlisting}
\end{center}
All the informative content is maintained. At this point, the memory footprint of the dataset is at his peak, because it contains all the previous fields both of the original objects, query and search documents.\\
As mentioned in Chapter 4, the dataset is composed by one hundred query-search documents coupled: these couples have been decided in a qualitative way, choosing the right documents for each query. For each query there are five documents that are strongly correlated to it and five documents that are not correlated at all. This organization is useful both form the point of view of evaluation (as previously mentioned in Chapter 4), but it is also useful from a computational point of view, given that the dataset is rather small.
An idea of the resulting dataset is visible in Table \ref{dataset_shape}, for sake of brevity some information have been omitted.
\begin{table}[H]
\centering
    \begin{tabular}{||c | c c||} 
     \hline
     Query key & Document key & Related\\ [0.5ex] 
     \hline\hline
     query\_key\_0 & document\_key & true \\ 
     \hline
     \dots & \dots & \dots\\
     \hline
     query\_key\_0 & document\_key & false\\
     \hline
     \dots & \dots & \dots\\
     \hline
     query\_key\_9 & document\_key & true \\ 
     \hline
     \dots & \dots & \dots\\
     \hline
     query\_key\_9 & document\_key & false\\
     \hline
    \end{tabular}
    \caption{Resulting dataset}
     \label{dataset_shape}
\end{table}
As visible, for each query identified by \emph{query\_key\_n}, there are multiple documents associated with an attribute called \emph{Related} indicating ndicating whether a document is closely related to the query.
\subsection{Transformer models}
As said in Chapter 4, the model choice is the biggest discriminant for the final result. In Chapter 2 was presented the original transformer architecture based on Vaswani's paper \cite{vaswani2017attention}. Such technology has been further enhanced in order to obtain way more usable and representative embeddings as described in Chapter 4. 
\subsection{Libraries and modules}
\subsubsection{NumPy}
NumPy is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more \cite{harris2020array}.
\paragraph{The \emph{ndarray}} is the core of the NumPy package, which encapsulates different n-dimensional arrays of homogeneous data types. There are several important differences between NumPy arrays and the standard Python lists.
\begin{enumerate}
    \item \textbf{Array size}: NumPy array that have a fixed size at creation, unlike Python lists (which can grow dynamically). Changing the size of an ndarray will create a new array and delete the original one.
    \item \textbf{Element type}: elements in a NumPy array are all required to be of the same data type, and thus will be the same size in memory.
    \item \textbf{Mathematical operations}: NumPy arrays facilitate advanced mathematical and other types of operations on large numbers of data. Typically, such operations are performed more efficiently and with less code than using Python’s built-in lists.
    \item \textbf{Advanced libraries}: the growing plethora of scientific and mathematical Python-based packages are using NumPy arrays; though these typically support Python-sequence input, they convert such input to NumPy arrays prior to processing, and they often output NumPy arrays. In other words, in order to efficiently use much (perhaps even most) of today’s scientific/mathematical Python-based software, just knowing how to use Python’s built-in sequence types is insufficient -- one also needs to know how to use NumPy arrays.
\end{enumerate}
\subsubsection{SciPy}
SciPy is a collection of mathematical algorithms and convenience functions built on the NumPy extension of Python. It adds significant power to the interactive Python session by providing the user with high-level commands and classes for manipulating and visualizing data. With SciPy, an interactive Python session becomes a data-processing and system-prototyping environment rivaling systems, such as MATLAB, IDL, Octave, R-Lab, and SciLab.
The additional benefit of basing SciPy on Python is that this also makes a powerful programming language available for use in developing sophisticated programs and specialized applications. Scientific applications using SciPy benefit from the development of additional modules in numerous niches of the software landscape by developers across the world. Everything from parallel programming to Web and data-base subroutines and classes have been made available to the Python programmer. All of this power is available in addition to the mathematical libraries in SciPy \cite{2020SciPyNMeth}.
\subsubsection{Transformers}
Huggingface \emph{Transformers} library provides thousands of pretrained models to perform tasks on texts such as classification, information extraction, question answering, summarization, translation, text generation and more in over 100 languages \cite{Wolf_Transformers_StateoftheArt_Natural_2020}.
\subsubsection{scikit-learn}
\emph{Scikit-learn} is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection and evaluation, and many other utilities \cite{scikit-learn}.
\subsubsection{NetworkX}
\emph{NetworkX} is a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks. With NetworkX one can load and store networks in standard and nonstandard data formats, generate many types of random and classic networks, analyze network structure, build network models, design new network algorithms, draw networks, and much more \cite{SciPyProceedings_11}.
\subsubsection{html}
\emph{html} is a module that defines a class HTMLParser which serves as the basis for parsing text files formatted in HTML (HyperText Mark-up Language) and XHTML. It has been used to clean up all the HTML tags and special characters present inside the body of the textual documents \cite{html_parser}.
\subsubsection{re}
\emph{re} is a module that module provides regular expression matching operations. Regular expressions are character patterns used to match different portions of a string. It is possible to manage these sub-strings, replacing, deleting, modifying the characters within the,. This module is heavily used for cleaning and splitting operations \cite{re}.
\subsubsection{SentenceTransformers}
\emph{SentenceTransformers} is a Python framework for state-of-the-art sentence, text and image embeddings. This library abstracts some of the biggest problems of transformers, like sentence length, embedding averaging, even similarity is provided inside the package. In this project, it has been only used the embedding extraction part that takes car of all the concerning aspects \cite{sentence-transformers}.
\subsubsection{Plotly}
\emph{Plotly's} \cite{plotly} Python graphing library makes interactive, publication-quality graphs. Built on top of the Plotly JavaScript library (plotly.js), plotly enables Python users to create beautiful interactive Web-based visualizations that can be displayed in Jupyter notebooks, saved to standalone HTML files, or served as part of pure Python-built Web applications using Dash. Plotly became useful for the realization of some more interactive graphs and charts, like when graphs have been plotted for debug purpose.
\subsection{Cluster settings}
In order to perform all the experiments, we have used the following cluster configuration:
\begin{enumerate}
    \item \textbf{Environment}: Databricks;
    \item \textbf{Cluster dimension}: 13 nodes cluster;
    \item \textbf{Programming language}: Python=3.7.10;
    \item \textbf{Spark version}: PySpark=3.1.2;
    \item \textbf{Libraries}: 
        \begin{enumerate}
            \item numpy=1.18.1;
            \item scikit-learn=0.22.1;
            \item transformers=4.10.2;
            \item sentence-transformers=2.0.0;
            \item html=3.4;
            \item re=2.2.1;
            \item scipy=1.7.1;
            \item networkx=2.6.3;
            \item plotly=5.3.1;
        \end{enumerate}
\end{enumerate}
This setting allowed to execute an entire experiment, from dataset cleaning to evaluation, in a time between one and three hours, depending on the transformer model.

\section{Results}
Using a different combination of hyperparameters for each execution led to a series of different experiments. Each experiment consisted in a combination of: transformer models, numerosity reduction similarity thresholds and voting techniques. Algorithms working with previously mentioned hyperparameters have been explained in Chapter 4.\\
In Table \ref{tab:model_name_model_label} is visible the association between model label, model name and result entry in Tables \ref{tab:experimental_results_complete} and \ref{tab:experimental_results_best}. For readability reasons, each model name has been converted to a shorter and more readable label.
\begin{table}[H]
    \centering
    \resizebox{\textwidth}{!}{
    \begin{tabular}{| c | c | c |}
        \hline
        Label & Model & Table entry\\ 
        \hline
        STSBMpnetBaseV2 & stsb-mpnet-base-v2 & Mpnet     \\
        ParaphraseAlbertBaseV2 & paraphrase-albert-base-v2 & PAlbert     \\
        ParaphraseXlmRMultilingualV1 & paraphrase-xlm-r-multilingual-v1 & Xlm    \\
        AlbertBaseV2 & albert-base-v2 & Albert     \\
        DistilbertBaseMultilingualCased & distilbert-base-multilingual-cased & Distilbert     \\ 
        \hline
    \end{tabular}
    }
    \caption{Model name - Model label - Table entry correspondence}
    \label{tab:model_name_model_label}
\end{table}

\subsection{Result discussion}
In this subsection there is a discussion about some important aspects of the results that have emerged by our experiments. \\
The first important aspect that emerges from performed experiments is that models trained using two specific datasets achieve better results overall than other models. As visible from Table \ref{tab:experimental_results_complete}, using models trained using a set of sentence pairs with a similarity score, like \emph{stsb-mpnet-base-v2} (Mpnet), and models trained using paraphrase datasets, like \emph{paraphrase-albert-base-v2} (PAlbert), show better result overall than other generic models and are visible in Table \ref{tab:experimental_results_best}. Those models show a very good result for \emph{Precision@100}, which measures the percentage of right positioned documents in relation to the input query, meaning that the framework is able to assign right documents to right queries, but it's interesting to notice also that they can separate quite well right documents form wrong ones, as visible looking at \emph{Difference mean}, which measures the difference between the mean of correlated documents and not related documents, and \emph{Difference median} metrics, which measures the difference between the median similarity score of correlated documents and not related documents. Median proves to be a better voting technique then mean due to its greater robustness to outliers.
\begin{table}[H]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{||c|c|c|c|c|c||}
\hline
Model & P@100 & Diff mean & Diff median & Red ratio \% & Voting tech \\
\hline\hline
Mpnet       & 0,88 & 0,13  & 0,12 & 9,88  & median \\
PAlbert     & 0,86 & 0,1   & 0,11 & 6,52  & median \\
Mpnet       & 0,86 & 0,12  & 0,12 & 11,49 & median \\
PAlbert     & 0,84 & 0,1   & 0,1  & 2,63  & median \\
PAlbert     & 0,84 & 0,09  & 0,1  & 10,87 & mean \\
Mpnet       & 0,84 & 0,12  & 0,12 & 15,72 & mean \\
\hline
\end{tabular}
}
\caption{Best results table}
\label{tab:experimental_results_best}
\end{table}
Secondly, the implemented numerosity reduction shows a result conservation useful if cluster usage is a concern: reducing space occupation and maintaining similar result is considerable as an achievement. The first line of Table \ref{tab:experimental_results_complete}, which is the best result achieved, shows how a 10\% reduction of the number of sentences in the corpus doesn't influence the final result while using a reduction threshold of 0.4. Recalling Chapter 4, \emph{Red \%} visible in Tables \ref{tab:experimental_results_best} \ref{tab:result_conservation} and \ref{tab:experimental_results_complete} is the threshold used in the numerosity reduction phase. Table \ref{tab:result_conservation} highlights this phenomena and shows that these models, in the scope of the project, don't face a result degradation when the number of sentences is reduced. When dealing with big data this could become useful to reduce disk and memory occupation, resulting in shorter read and write times. Moreover, working on a smaller dataset tend to reduce computational time, which may be very costly depending on the cluster setting. Obviously, this approach works well on a dataset built like the one used during the project, it needs further tests to see how it behaves on differently built datasets. 
\begin{table}[H]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{||c|c|c|c|c|c|c||}
\hline
Model & P@100 & Diff mean & Diff median & Red ratio \% & Voting tech & Red \% \\
\hline\hline
 Mpnet      & 0,88 & 0,13  & 0,12 & 9,88  & median & 0,4 \\
 Mpnet      & 0,88 & 0,13  & 0,13 & 0     & median & 0   \\
 PAlbert    & 0,86 & 0,1   & 0,11 & 6,52  & median & 0,4 \\
 PAlbert    & 0,86 & 0,1   & 0,11 & 0     & median & 0   \\
\hline
\end{tabular}
}
\caption{Result conservation}
\label{tab:result_conservation}
\end{table}
Thirdly, Table \ref{tab:experimental_results_complete} show that for the project scope is generally better to use a monolingual model (in our case English) instead of using a multilingual one. This happens because retraining a model like BERT, ALBERT, \dots is very demanding and usually is performed by big companies (Google, Facebook, \dots) or universities (University of Darmstadt, University of Massachusetts, \dots) leading to the majority of models being specialized on English. To emphasize this, going on Huggingface website \cite{huggingface_models} is visible that for the task of semantic similarity there are 383 models while just 1 Italian, 9 French, 3 German, \dots \\
Fourthly, Table \ref{tab:experimental_results_complete} show that for the project scope is generally better to use median as voting technique (Chapter 4) in order to compute the final result, as it output the best results. This happens due to the median higher robustness to outliers when compared to the mean: the reason for this is that the mean can be dragged up or down by extreme values, but since the median is just the middle value in a distribution, it is not influenced by the outliers.\\
Lastly, not furtherly specialized models like \emph{albert-base-v2} (AlbertBaseV2) and \emph{distilbert-base-multilingual-cased} (DistilbertBaseMultilingualCased) show worse results than others. In the project scope, is demonstrated that using those models doesn't reach good enough performances, emphasizing even more the concept that the model choice is crucial for a system like the one presented in this document and that the choice operation needs a big attention in order to make the best choice. 
\newpage

Table \ref{tab:experimental_results_complete} gathers the whole set of experimental result.
\begin{table}[ht]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{||c|c|c|c|c|c|c|c||}
\hline
Model & P@100 & Diff mean & Diff median & Multilang & Red ratio \% & Voting tech & Red \% \\
\hline\hline
\rowcolor{gray} Mpnet             & 0,88 & 0,13  & 0,12  & false & 9,88  & median & 0,4 \\
Mpnet                 & 0,88 & 0,13  & 0,13  & false & 0     & median & 0,1 \\
Mpnet                 & 0,88 & 0,13  & 0,13  & false & 0     & median & 0,2 \\
Mpnet                 & 0,88 & 0,13  & 0,13  & false & 0     & median & 0,3 \\
Mpnet                 & 0,88 & 0,13  & 0,13  & false & 0     & median & 0   \\
PAlbert          & 0,86 & 0,1   & 0,11  & false & 0     & median & 0,2 \\
\rowcolor{gray} PAlbert          & 0,86 & 0,1   & 0,11  & false & 6,52  & median & 0,4 \\
PAlbert          & 0,86 & 0,1   & 0,11  & false & 0     & median & 0   \\
Xlm    & 0,86 & 0,12  & 0,1   & true  & 0     & median & 0   \\
PAlbert          & 0,86 & 0,1   & 0,11  & false & 0,74  & median & 0,3 \\
PAlbert          & 0,86 & 0,1   & 0,11  & false & 0     & median & 0,1 \\
\rowcolor{gray} Mpnet                 & 0,86 & 0,12  & 0,12  & false & 11,49 & median & 0,5 \\
\rowcolor{gray} PAlbert          & 0,84 & 0,1   & 0,1   & false & 2,63  & median & 0,5 \\
Xlm    & 0,84 & 0,11  & 0,09  & true  & 3,64  & median & 0,5 \\
Mpnet                 & 0,84 & 0,12  & 0,12  & false & 0     & mean   & 0,2 \\
Mpnet                 & 0,84 & 0,12  & 0,12  & false & 0     & mean   & 0,1 \\
\rowcolor{gray} PAlbert          & 0,84 & 0,09  & 0,1   & false & 10,87 & mean   & 0,5 \\
Mpnet                 & 0,84 & 0,12  & 0,12  & false & 8,62  & mean   & 0,4 \\
Mpnet                 & 0,84 & 0,12  & 0,12  & false & 6,4   & mean   & 0,3 \\
\rowcolor{gray} Mpnet                 & 0,84 & 0,12  & 0,12  & false & 15,72 & mean   & 0,5 \\
Mpnet                 & 0,84 & 0,12  & 0,12  & false & 0     & mean   & 0   \\
PAlbert          & 0,82 & 0,1   & 0,11  & false & 0     & mean   & 0,2 \\
PAlbert          & 0,82 & 0,1   & 0,11  & false & 0     & mean   & 0,1 \\
PAlbert          & 0,82 & 0,1   & 0,11  & false & 5,56  & mean   & 0,3 \\
PAlbert          & 0,82 & 0,1   & 0,11  & false & 0     & mean   & 0   \\
PAlbert          & 0,82 & 0,1   & 0,11  & false & 2,67  & mean   & 0,4 \\
Xlm    & 0,8  & 0,1   & 0,1   & true  & 1,69  & mean   & 0,5 \\
Xlm    & 0,8  & 0,11  & 0,11  & true  & 0     & mean   & 0   \\
Albert                    & 0,74 & 0,02  & 0,02  & false & 0     & median & 0   \\
Distilbert & 0,74 & 0,04  & 0,05  & true  & 0     & median & 0   \\
\hline
\end{tabular}
}
\caption{Experimental results}
\label{tab:experimental_results_complete}
\end{table}

\begin{table}[t]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{||c|c|c|c|c|c|c|c||}
\hline
Model & P@100 & Diff mean & Diff median & Multilang & Red ratio \% & Voting tech & Red \% \\
\hline\hline
Albert                    & 0,72 & 0,02  & 0,02  & false & 0     & mean   & 0   \\
Distilbert & 0,72 & 0,04  & 0,04  & true  & 0     & mean   & 0   \\
Distilbert & 0,68 & 0,02  & 0,02  & true  & 79,73 & median & 0,1 \\
Distilbert & 0,64 & 0,01  & 0,03  & true  & 93,75 & mean   & 0,4 \\
Distilbert & 0,64 & 0,01  & 0,03  & true  & 96,52 & median & 0,4 \\
Distilbert & 0,62 & 0,01  & 0,02  & true  & 67,21 & mean   & 0,1 \\
Distilbert & 0,58 & 0     & 0,03  & true  & 97,47 & median & 0,5 \\
Distilbert & 0,58 & 0     & 0,03  & true  & 97,22 & mean   & 0,5 \\
Albert                    & 0,54 & 0 & 0,02  & false & 96,67 & mean   & 0,1 \\
Albert                    & 0,54 & 0 & 0,02  & false & 96,15 & median & 0,1 \\
Distilbert & 0,54 & 0,01  & 0     & true  & 84,48 & mean   & 0,2 \\
Distilbert & 0,5  & 0     & 0     & true  & 87,5  & median & 0,3 \\
Distilbert & 0,5  & 0,01  & 0     & true  & 71,88 & median & 0,2 \\
Distilbert & 0,5  & 0     & 0     & true  & 94,74 & mean   & 0,3 \\
Albert                    & 0,48 & 0     & 0     & false & 96,08 & mean   & 0,5 \\
Albert                    & 0,48 & 0     & 0 & false & 94,44 & mean   & 0,3 \\
Albert                    & 0,48 & 0     & 0     & false & 95    & median & 0,5 \\
Albert                    & 0,48 & 0     & 0 & false & 94,44 & median & 0,3 \\
Albert                    & 0,48 & 0 & 0 & false & 95,56 & mean   & 0,2 \\
Albert                    & 0,48 & 0     & 0     & false & 96,08 & mean   & 0,4 \\
Albert                    & 0,48 & 0 & 0 & false & 97,37 & median & 0,2 \\
Albert                    & 0,48 & 0     & 0     & false & 96,08 & median & 0,4 \\
\hline
\end{tabular}
}
\caption{Continued from previous table}
\end{table}



\end{document}